{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a734789",
   "metadata": {},
   "source": [
    "# Breaking down the document into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69513fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def chunk_by_sentences(text, max_tokens=20):\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    total_tokens = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        token_count = len(tokens)\n",
    "\n",
    "        if total_tokens + token_count > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            total_tokens = 0\n",
    "\n",
    "        current_chunk.append(sentence)\n",
    "        total_tokens += token_count\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "full_text = \"\"\"Ayutthaya, located in the central plains of Thailand, is a city steeped in history and cultural significance. \n",
    "              Established in 1350 by King U Thong, it became the second capital of the Siamese Kingdom after Sukhothai. \n",
    "              Over the course of more than four centuries, Ayutthaya flourished as one of the world‚Äôs most important trading and diplomatic hubs. \n",
    "              Its strategic location between China, India, and the Malay Archipelago allowed it to attract merchants from Europe, the Middle East, and across Asia. \n",
    "              The city was renowned for its grandeur, boasting impressive temples, royal palaces, and advanced urban planning, all surrounded by a network of rivers that served as natural defenses.\n",
    "              Ayutthaya was a melting pot of cultures, where Thai, Khmer, Chinese, Japanese, Portuguese, Dutch, and French communities lived and traded side by side. \n",
    "              Its architecture reflected this diversity, blending traditional Thai styles with foreign influences in everything from temples to fortifications. \n",
    "              Unfortunately, in 1767, the city fell to Burmese invaders, who looted and burned much of it to the ground. \n",
    "              Despite this devastation, the ruins of Ayutthaya still stand as a powerful reminder of the city‚Äôs former glory. \n",
    "              Today, the Ayutthaya Historical Park, a UNESCO World Heritage Site, preserves many of the ancient structures, such as Wat Phra Si Sanphet, Wat Mahathat, and the iconic Buddha head entwined in tree roots. \n",
    "              These ruins attract visitors from around the world who come to witness the beauty and historical depth of a civilization that once stood at the crossroads of global trade and diplomacy.\n",
    "            \"\"\"\n",
    "\n",
    "chunks = chunk_by_sentences(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15e0e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Ayutthaya, located in the central plains of Thailand, is a city steeped in history and cultural significance.',\n",
       " 'Established in 1350 by King U Thong, it became the second capital of the Siamese Kingdom after Sukhothai.',\n",
       " 'Over the course of more than four centuries, Ayutthaya flourished as one of the world‚Äôs most important trading and diplomatic hubs.',\n",
       " 'Its strategic location between China, India, and the Malay Archipelago allowed it to attract merchants from Europe, the Middle East, and across Asia.',\n",
       " 'The city was renowned for its grandeur, boasting impressive temples, royal palaces, and advanced urban planning, all surrounded by a network of rivers that served as natural defenses.',\n",
       " 'Ayutthaya was a melting pot of cultures, where Thai, Khmer, Chinese, Japanese, Portuguese, Dutch, and French communities lived and traded side by side.',\n",
       " 'Its architecture reflected this diversity, blending traditional Thai styles with foreign influences in everything from temples to fortifications.',\n",
       " 'Unfortunately, in 1767, the city fell to Burmese invaders, who looted and burned much of it to the ground.',\n",
       " 'Despite this devastation, the ruins of Ayutthaya still stand as a powerful reminder of the city‚Äôs former glory.',\n",
       " 'Today, the Ayutthaya Historical Park, a UNESCO World Heritage Site, preserves many of the ancient structures, such as Wat Phra Si Sanphet, Wat Mahathat, and the iconic Buddha head entwined in tree roots.',\n",
       " 'These ruins attract visitors from around the world who come to witness the beauty and historical depth of a civilization that once stood at the crossroads of global trade and diplomacy.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a151206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of chunks:\", len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be54e845",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7995221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Two-level indexing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `chunk_metadata` is a list of dicts like:\n",
    "# [{\"doc_id\": \"doc1\", \"section\": \"intro\", \"text\": \"...\"}, ...]\n",
    "# Or at minimum: [{\"doc_id\": \"doc1\", \"text\": \"...\"}, ...]\n",
    "\n",
    "# Example: simulate grouped chunks\n",
    "chunk_metadata = [{\"doc_id\": f\"doc_{i//5}\", \"text\": chunk} for i, chunk in enumerate(chunks)]\n",
    "\n",
    "# Step 1: Group by document\n",
    "grouped_docs = defaultdict(list)\n",
    "for meta in chunk_metadata:\n",
    "    grouped_docs[meta[\"doc_id\"]].append(meta[\"text\"])\n",
    "\n",
    "# Step 2: Load embedder\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 3: Build per-document (Level 1) and chunk-level (Level 2) FAISS indexes\n",
    "level1_doc_ids = []\n",
    "level1_doc_embeddings = []\n",
    "\n",
    "level2_indexes = {}  # doc_id -> FAISS index\n",
    "level2_chunks = {}   # doc_id -> chunk list\n",
    "\n",
    "for doc_id, chunk_list in grouped_docs.items():\n",
    "    # Level 2: Chunk-level index\n",
    "    chunk_embeddings = embedder.encode(chunk_list, convert_to_numpy=True)\n",
    "    dim = chunk_embeddings.shape[1]\n",
    "    idx = faiss.IndexFlatL2(dim)\n",
    "    idx.add(chunk_embeddings)\n",
    "    level2_indexes[doc_id] = idx\n",
    "    level2_chunks[doc_id] = chunk_list\n",
    "\n",
    "    # Level 1: Document-level representation (mean embedding)\n",
    "    doc_embedding = chunk_embeddings.mean(axis=0)\n",
    "    level1_doc_embeddings.append(doc_embedding)\n",
    "    level1_doc_ids.append(doc_id)\n",
    "\n",
    "# Step 4: Save Level 1 index\n",
    "dim = level1_doc_embeddings[0].shape[0]\n",
    "level1_index = faiss.IndexFlatL2(dim)\n",
    "level1_index.add(np.array(level1_doc_embeddings))\n",
    "\n",
    "faiss.write_index(level1_index, \"level1_index.faiss\")\n",
    "with open(\"level1_doc_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(level1_doc_ids, f)\n",
    "\n",
    "# Step 5: Save Level 2 indexes\n",
    "for doc_id, idx in level2_indexes.items():\n",
    "    faiss.write_index(idx, f\"level2_index__{doc_id}.faiss\")\n",
    "    with open(f\"level2_chunks__{doc_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(level2_chunks[doc_id], f)\n",
    "\n",
    "print(\"‚úÖ Two-level indexing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c643c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb903dfd",
   "metadata": {},
   "source": [
    "# Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80143070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieved Chunks:\n",
      " Ayutthaya, located in the central plains of Thailand, is a city steeped in history and cultural significance.\n",
      "---\n",
      "Over the course of more than four centuries, Ayutthaya flourished as one of the world‚Äôs most important trading and diplomatic hubs.\n",
      "---\n",
      "Ayutthaya was a melting pot of cultures, where Thai, Khmer, Chinese, Japanese, Portuguese, Dutch, and French communities lived and traded side by side.\n",
      "---\n",
      "Despite this devastation, the ruins of Ayutthaya still stand as a powerful reminder of the city‚Äôs former glory.\n",
      "---\n",
      "Today, the Ayutthaya Historical Park, a UNESCO World Heritage Site, preserves many of the ancient structures, such as Wat Phra Si Sanphet, Wat Mahathat, and the iconic Buddha head entwined in tree roots.\n",
      "---\n",
      "These ruins attract visitors from around the world who come to witness the beauty and historical depth of a civilization that once stood at the crossroads of global trade and diplomacy.\n",
      "\n",
      "üß† Answer:\n",
      " Answers:\n",
      "\n",
      "1. When was Ayutthaya established and by whom ?\n",
      "\n",
      "Ayutthaya was established in 1350 by King Ramathibodi I, who was the first king of the Ayutthaya Kingdom.\n",
      "\n",
      "2. What is the current status of Ayutthaya Historical Park and what is its significance ?\n",
      "\n",
      "Ayutthaya Historical Park is a UNESCO World Heritage Site that preserves many of the ancient structures, such as Wat Phra Si Sanphet, Wat Mahathat, and the iconic Buddha head entwined in tree roots.\n",
      "\n",
      "3. What cultural significance does Ayutthaya hold for Thai people and what is its impact on Thai society today ?\n",
      "\n",
      "Ayutthaya holds a significant cultural and historical significance for Thai people. It is a symbol of Thailand‚Äôs rich cultural heritage and a testament to the country‚Äôs long and complex history.\n",
      "\n",
      "Ayutthaya has had a profound impact on Thai society, shaping the country‚Äôs identity and values. It has also served as a model for other Southeast Asian countries seeking to preserve their cultural\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load Level 1 document index and IDs\n",
    "level1_index = faiss.read_index(\"level1_index.faiss\")\n",
    "with open(\"level1_doc_ids.pkl\", \"rb\") as f:\n",
    "    level1_doc_ids = pickle.load(f)\n",
    "\n",
    "# Load embedder\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load local LLM (TinyLlama or any other)\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Step 1: Hierarchical Retrieval\n",
    "def retrieve(query, top_docs=3, top_chunks=2):\n",
    "    # Embed the query\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Level 1: retrieve top documents\n",
    "    _, doc_indices = level1_index.search(query_embedding, top_docs)\n",
    "    selected_doc_ids = [level1_doc_ids[i] for i in doc_indices[0]]\n",
    "\n",
    "    retrieved_chunks = []\n",
    "\n",
    "    for doc_id in selected_doc_ids:\n",
    "        # Load Level 2 index and chunks for that document\n",
    "        level2_index = faiss.read_index(f\"level2_index__{doc_id}.faiss\")\n",
    "        with open(f\"level2_chunks__{doc_id}.pkl\", \"rb\") as f:\n",
    "            doc_chunks = pickle.load(f)\n",
    "\n",
    "        # Level 2: search for best chunks within this document\n",
    "        _, chunk_indices = level2_index.search(query_embedding, top_chunks)\n",
    "        retrieved_chunks.extend([doc_chunks[i] for i in chunk_indices[0]])\n",
    "\n",
    "    return retrieved_chunks\n",
    "\n",
    "# Step 2: Generation\n",
    "def generate_answer(query, context_docs):\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "    prompt = f\"\"\"[INST] Use the following context to answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion: {query} [/INST]\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096).to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"[/INST]\")[-1].strip()\n",
    "\n",
    "# Step 3: Run example\n",
    "query = \"When was Ayutthaya established and by whom ?\"\n",
    "retrieved = retrieve(query)\n",
    "answer = generate_answer(query, retrieved)\n",
    "\n",
    "print(\"üîç Retrieved Chunks:\\n\", \"\\n---\\n\".join(retrieved))\n",
    "print(\"\\nüß† Answer:\\n\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
